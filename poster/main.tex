\documentclass[15pt,margin=1in,innermargin=-4.5in,blockverticalspace=-0.25in]{tikzposter}
\geometry{paperwidth=42in,paperheight=30in}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{enumitem}
\usepackage[backend=biber,style=numeric]{biblatex}
\usepackage{emory-theme}
\renewcommand{\familydefault}{\sfdefault}

\usepackage{mwe} % for placeholder images

\addbibresource{refs.bib}

% set theme parameters
\tikzposterlatexaffectionproofoff
\usetheme{EmoryTheme}
\usecolorstyle{EmoryStyle}

\title{\textbf{Reproduction of `Multi-Task Learning using Uncertainty to Weigh Losses'}}
\author{D. Baerg, O. Key, J. Materzynska, M. Tong}
\institute{Department of Computer Science, University of Oxford}
\titlegraphic{\qquad \qquad \qquad \qquad \qquad  \includegraphics[width=0.06\textwidth]{oxford.jpg}}

% begin document
\begin{document}
\maketitle


\centering
\begin{columns}
    \column{0.32}

    \block{A new approach to multi-task learning}{
             
        Paper on `Multi-Task Learning using Uncertainty to Weigh Losses' -- Kendall, Gal \& Cipolla, 2017.
        \begin{itemize}
        \item Principled approach to multi-task learning, demonstrated on the multi-task problem of semantic segmentation, instance segmentation and depth regression for the Cityscapes dataset
        
        \begin{tikzfigure}[Model architecture (Kendall et al., 2017)]
            \includegraphics[width=1\linewidth]{overall}
        \end{tikzfigure}
        
        \item 3 key contributions:
        \begin{enumerate}
       \item  Aleatoric homoscedastic uncertainty to weigh losses in different tasks
       \item  Unified architecture for all three tasks with the same encoder for different tasks, with a separate decoder for each task
       \item Demonstrating that loss weighting is important for performance, and showing how superior performance can be achieved on multi-task models compared to individually trained single-task models
       \end{enumerate}
       \end{itemize}
                    }
       
    
    \block{Selected reproduction objective}{
    
       \begin{itemize}
       
       \item Comparison of multi-task learning with single-task learning and learned loss weights with fixed loss weights
       \item Subsampled dataset, Tiny Cityscapes, requires less computation time
       
       \end{itemize}
    
       \begin{tikzfigure}[Results that we aimed to reproduce (Kendall et al., 2017)]
            \includegraphics[width=1\linewidth]{data.png}
        \end{tikzfigure}
        
    }
   
   \column{0.36} 
   \block{Technical details}{
       \begin{itemize}
       \item Overall joint loss function: 
       \[ \mathcal{L} \approx 
       \frac{1}{\sigma^2_\text{sem}} \mathcal{L}_\text{sem}  + \log \sigma_\text{sem}
       + \frac{1}{2\sigma^2_\text{ins}} \mathcal{L}_\text{ins}+ \log \sigma_\text{ins}
       + \frac{1}{2\sigma^2_\text{dep}} \mathcal{L}_\text{dep}
        + \log \sigma_\text{dep} 
  \]
     
  \item Model architecture
\begin{itemize}
\item DeepLabv3 encoder architecture, including ResNet-101 layers with dilated convolutions and Atrous Spatial Pooling Pyramid module to increase contextual awareness
\item Simple decoder architecture with two convolutional layers for each task
\end{itemize}
\end{itemize}
       
    }
    
    \block{Reproduction results}{

   	\begin{itemize}
   	\item 
	
	
	 \vspace{0.5em}
	\begin{center}
   	\begin{tabular}{c| c | c | c| c |c }
  	\hline			
  	  \multicolumn{3}{c|}{Task weights} & $\>$ Segment. $\>$ &Instance& $\>$ Inv. depth$\>$ \\
	
	 $\>$Seg.$\>$ &$\>$ Inst.$\>$ &$\>$ Depth$\>$ & IoU &  $\>$ mean error $\>$  & $\>$ mean error$\>$ \\
	\hline
  	 1 		& 0 	& 0			&33.2\% 	& -			&-\\
  	  0  	&  1 	& 0 		& -			&\textbf{5.3}	&-\\
	 0 		& 0 	&	1		&-			& -			& 0.45 \\ \hline 
	 0.333 & 0.333 & 0.333 		& 32.3\% 	& 5.7		& 0.46 \\
	 0.89 	&0.01	&0.1		&32.7 \%	&8.4		&0.53\\ \hline
	  $\:$ Learned $\:$ &	$\:$ Learned$\:$ 	& - 	&33.9\%		&7.2		& - \\
	 $\:$ Learned$\:$  & - &$\:$  Learned 	$\:$ 	& 33.2\% 	& - 		& 0.43 \\
	 - &$\:$  Learned $\:$ & $\:$ Learned $\:$ 		& - 		& 6.3		& 0.43 \\\hline
	 $\:$ Learned$\:$  &$\:$  Learned $\:$ & $\:$ Learned	$\:$ &\textbf{34.0\%} & 5.8 & \textbf{0.42} \\
 	 \hline  
	\end{tabular}
	\end{center}
   \vspace{0.5em}
	
	
	\item LR search: 596, 591, 592, 593
s
   
    \end{itemize} 
         
    }

    
    \column{0.32}
    \block{Success on other multi-task problems}{
    
    \begin{itemize}
    \item Applying the principled approach to Fashion MNIST classification and reconstruction yields a learned weights multi-task model which outperforms individually trained models and fixed weights multi-task model
    
    \vspace{0.5em}
	\begin{center}
   	\begin{tabular}{c | c | c| c }
  	\hline			
  	  \multicolumn{2}{c|}{Task weights} & $\>$ Classification $\>$ & $\>$ Reconstruction$\>$ \\
	
	 $\>$Classif.$\>$ &$\>$ Reconstr.$\>$ & accuracy & error \\
	\hline
  	 1  & 0  &89.7\% & -\\
  	  0  &  1& -& 0.087\\
	 0.5 & 0.5 &89.3\%& 0.085 \\ \hline 
	 \multicolumn{2}{c|}{Learned}& \textbf{90.2\%} & \textbf{0.075} \\
 	 \hline  
	\end{tabular}
	\end{center}
   \vspace{0.5em}
	\item Reconstruction output sample from learned weights multi-task model
	
	\begin{tikzfigure}
            \includegraphics[width=0.7\linewidth]{shirt.png}
        \end{tikzfigure}
        
	\item Optimal weight search
	
	\begin{tikzfigure}
            \includegraphics[width=0.8\linewidth]{optimal.png}
        \end{tikzfigure}

   \end{itemize}   
    }
   
\end{columns}
\end{document}